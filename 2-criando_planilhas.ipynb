{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from warnings import filterwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo arquivos netCDF\n",
    "diretorio = r'C:\\IC\\netCDF'\n",
    "\n",
    "# Listando arquivos\n",
    "arquivos = sorted([os.path.join(diretorio, arquivo) for arquivo in os.listdir(diretorio) if arquivo.endswith('.nc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo arquivo de coordenadas\n",
    "pontos = pd.read_csv(r'C:\\IC\\Scripts2\\pontos.csv', sep=',')\n",
    "\n",
    "# listando coordenadas\n",
    "latitudes = pontos['lat'].values\n",
    "longitudes = pontos['lon'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrigindo longitude\n",
    "for arquivo in arquivos:\n",
    "    # Abrindo arquivo netCDF\n",
    "    netCDF = xr.open_dataset(arquivo)\n",
    "\n",
    "    # Filtrando coordenadas\n",
    "    longitude_corrigida = netCDF['longitude'].values\n",
    "\n",
    "    # Corrigindo longitude\n",
    "    longitude_corrigida[longitude_corrigida > 180] = longitude_corrigida[longitude_corrigida > 180] - 360\n",
    "\n",
    "    # Salvando coordenadas corrigidas\n",
    "    netCDF.to_netcdf(arquivo.replace('.nc', '_corrigido.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diretório dos arquivos corrigidos\n",
    "diretorio_corrigido = r'C:\\IC\\netCDF\\corrigido'\n",
    "\n",
    "# Listando arquivos\n",
    "arquivos_corrigido = sorted([os.path.join(diretorio_corrigido, arquivo) for arquivo in os.listdir(diretorio_corrigido) if arquivo.endswith('.nc')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando dataframe\n",
    "dataset = pd.DataFrame(columns=['data','horario', 'latitude', 'longitude', 'chuva'])\n",
    "\n",
    "# laço que percorre todos os arquivos e relaciona com os pontos no arquivo csv\n",
    "for arquivo in arquivos_corrigido:\n",
    "    \n",
    "    # pegando a data e horário do nome do arquivo\n",
    "    data,horario = arquivo[35:43], arquivo[43:45]\n",
    "\n",
    "    # Abrindo arquivo netCDF\n",
    "    netCDF = xr.open_dataset(arquivo)\n",
    "\n",
    "    # Acessando variável de interesse\n",
    "    netCDF = netCDF['prec']\n",
    "\n",
    "    # laço que percorre todos os pontos\n",
    "    for i in range(len(pontos)):\n",
    "\n",
    "        # Pegando o valor de chuva em um ponto\n",
    "        chuva = netCDF.sel(latitude=pontos.iloc[i].values[0], longitude=pontos.iloc[i].values[1], method='nearest').values\n",
    "        \n",
    "        # preenchendo o dataframe com linhas\n",
    "        linha = [data, horario, pontos.iloc[i].values[0], pontos.iloc[i].values[1], chuva]\n",
    "\n",
    "        # adicionando na ultima linha ao dataframe\n",
    "        dataset.loc[len(dataset)] = linha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste futuro para padronização das Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrigindo valores de data\n",
    "dataset['data'] = pd.to_datetime(dataset['data'], format='%Y%m%d')\n",
    "\n",
    "# transformando datetime para string\n",
    "dataset['data'] = dataset['data'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscando a coluna horário e substituindo os valores de 0 para 24\n",
    "dataset.loc[dataset['horario'] == 0, 'horario'] = 24\n",
    "\n",
    "# Datas para padronizar \n",
    "datas = ['2016-01-17', '2020-12-24', '2021-10-29']\n",
    "\n",
    "# Buscando a coluna data e substituindo os dias \n",
    "# dataset.loc[dataset['data'].isin(datas), 'datas'] = '2016-01-01 00:00:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajuste fino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegando os dados únicos de chuva\n",
    "datas = merge['data'].unique()\n",
    "\n",
    "# transformando chuva horária para acumulado\n",
    "for data in datas:\n",
    "    for _,row in pontos.iterrows():\n",
    "        lat = row[0]\n",
    "        lon = row[1]\n",
    "        merge.loc[(merge['data'] == data) & (merge['latitude'] == lat) & (merge['longitude'] == lon), 'chuva'] = merge.loc[(merge['data'] == data) & (merge['latitude'] == lat) & (merge['longitude'] == lon), 'chuva'].cumsum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando o dataframe em um arquivo csv\n",
    "dataset.to_csv(r'C:\\IC\\Scripts2\\dataset-merge.csv', sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
